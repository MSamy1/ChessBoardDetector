{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Muham\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Muham\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Muham\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Muham\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Keras Functional API Test\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import concatenate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "import load_models as lm\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "Datadir=\"C:/Users/Access/Board Detection App/\"\n",
    "path = os.path.join(Datadir, \"Test\")\n",
    "labels=[]\n",
    "training_data=[]\n",
    "img_size=30\n",
    "\n",
    "def create_model_empty_keras():\n",
    "    visible = Input(shape=(30,30,1))\n",
    "    conv1 = Conv2D(64, kernel_size=5, activation='relu')(visible)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(64, kernel_size=3, activation='relu')(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    flat = Flatten()(pool2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Create secondary model for pieces prediction input\n",
    "    input2=Input(shape=(12,))\n",
    "    hidden2 = Dense(12, activation='relu')(input2)\n",
    "    hidden3 = Dense(20, activation='relu')(hidden2)\n",
    "    hidden4 = Dense(10, activation='relu')(hidden3)\n",
    "    \n",
    "    #Merge 2 models\n",
    "    merge=concatenate([hidden4, flat])\n",
    "    \n",
    "    #Interpretation model\n",
    "    hidden1 = Dense(64, activation='relu')(merge)\n",
    "    output = Dense(1, activation='sigmoid')(hidden1)\n",
    "    \n",
    "    model = Model(inputs=[visible,input2], outputs=output)\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "   # model.load_weights('./model_weights_empty')\n",
    "    return model\n",
    "\n",
    "def create_training_data():\n",
    "    \n",
    "    for img in os.listdir(path):\n",
    "        img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "        #img_array=cv2.equalizeHist(img_array)\n",
    "        img_array=cv2.GaussianBlur(img_array,(3,3),0)\n",
    "        img_array=cv2.resize(img_array,(img_size,img_size))\n",
    "        training_data.append([img_array])\n",
    "        \n",
    "    X=[]\n",
    "    for feature in training_data:\n",
    "        X.append(feature)\n",
    "        \n",
    "    X=np.array(X).reshape(-1,img_size,img_size,1)\n",
    "    return X\n",
    "\n",
    "modele=create_model_empty_keras()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(modele, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1= create_training_data()\n",
    "X_test=X_test1/255.0\n",
    "#Create input2 (pieces model output)\n",
    "pieces_model=lm.create_model_pieces()\n",
    "x2=pieces_model.predict(X_test)\n",
    "\n",
    "y_predict=modele.predict([X_test,x2])\n",
    "y_predict=[round(num.max()) for num in y_predict]\n",
    "for i in range(len(X_test)):\n",
    "    image =X_test1[i].reshape(30,30)\n",
    "    cv2.imwrite(\"C:/Users/Access/Board Detection App/Test_resulte/\"+str(y_predict[i])+\"file\"+str(i)+\"-\"+str(y_predict[i])+\".png\",image)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
